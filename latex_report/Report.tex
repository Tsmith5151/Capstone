\documentclass{llncs}
\usepackage{graphicx}
\graphicspath{ {images/} }


\title{\textbf{Random Forest vs Logistic Regression for Binary Classification}}
\author{Kaitlin Kirasich, Trace Smith, and Bivin Sadler, PhD$^1$}
\institute{$^1$Master of Science in Data Science \\ Southern Methodist University \\ Dallas, Texas USA \\
\email{kkirasich@.smu.edu,traces@smu.edu,bsadler@smu.edu}}

\begin{document}
\maketitle

\begin{abstract} 
Selecting a learning algorithm to implement for a particular application on the basis of performance still remains an ad-hoc process using fundamental benchmarks such as evaluating a classifier’s overall loss function, area under the curve (AUC) score, specificity, and sensitivity values. This work is aimed at addressing the difficulty of model selection by evaluating the overall classification performance between random forest and logistic regression for datasets comprised of various underlying structures. A model evaluation tool was developed in R for simulating a variety of dataset characteristics in order to evaluate performance metrics such as true positive rate, false positive rate, and accuracy under specific conditions. Our findings indicate that when increasing the variance in the explanatory and noise variables, logistic regression consistently performed with a higher overall accuracy as compared to random forest.  However, the true positive rate for random forest was higher than logistic regression and yielded a higher false positive rate. In all cases a paired two sample t-test indicates there is enough evidence to suggest the false positive rate for random forest is statistically different than logistic regression. The model evaluation application developed in this work is a foundation for answering other intruiguing questions related to model performance under various treaments. 

\end{abstract}


\section{Introduction}

Datasets consist of various shapes and compositions, which poses the question, what data characteristics result in one machine learning algroithm outperforming others. When it comes to model selection, this is a constant challenge data scientist are often faced with. Training and evaluating multiple machine learning models for a given use case can be an expensive task computationally and time consuming. The analysis presented in this work is to provide insight into the relative performance of a learning algorithm conditioned on the particular characteristics of a dataset. To do so, random forest and logistic regression are two popular models that will be analyzed for comparing binary classification (y = {0,1}) performances with differing dataset structures. Both classifiers have been widely implemented in various domains and their successes have been well documneted. However, the particular characteristics of a dataset that make one model outperform the other is unknown as most published work compares overall performance between the two models for a single dataset. The objective of this study is to develop a statisitcal tool to directly observe the accuracy of each model by averaging the accuracy rate of 1000 random generations of a dataset with a desired structure.

Characteristics of a dataset can be comprised of missing values, outlier, highly correlated variables, concave or convex shapes, or subsets of the data that can be represented as clusters. Complex datasets that are not linearly seperable, or in other words, where a linear hyperplane splits the data into two halves such that the model poorly predicts the class label of the respected observation (Figure 1). One approach to infering underlying complexities of high-dimensional dataset is Topological Data Analysis (e.g. TDA), an evolving method that utilizes topological and geometric tools to identify relevant features in the data. Robust to noisy and incomplete datasets, TDA can be described as method that helps identify structures like clusters or other hidden shapes that can provide a more accurate representation of the dataset (Chazal et al, 2017). Models can then be trained on the new representaiton of the data that has been reconstructed, which has shown promising results. However, our analysis is aimed at preserving the raw structure of the data, such as altering the variance in the explanatory variables, or increasing and decreasing the number of observations or features in a multivariate dataset in order to draw conclusions into the performance of models like logistic regression and random forest under these types of conditions. Investigation into varying performance of machine learning algorithms for simple and complex data characteristics was the motivation behind this work. 

\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{decisionboundry.png}
\caption{R Shinny Application - Data Simulator}
\end{figure}


To conduct the analysis, a statistical tool was generated using RShiny to rapidly generate assorted multivariate datasets in order benchmark model performance under various conditions. To obtain an unbiased conclusions, the results from each case study considered in this work is an average of 1000 simulations, where each simulation is the product of a new dataset created that are under the same configuation. Key metrics, such as accuracy, area under the curve, true positive rate, false positive rate, and precision are also examined under the variety of data structures for performance comparison. Finally a pairwise two-sample t-test is conducted at the end of each simulation case study in order to provide statistical quantification as to whether a difference in model performance is conclusive enough to state the difference is significant or if the observed difference is by random chance. 


\section{Motivation}



\section{Data Set}

To conduct the statistical analysis, an interactive web application was developed using RShiny which allows end users to rapidly generate simulated datasets and evaluate performance metrics between machine learning models, random forest and logistic regression. For performing numerical simulations, creating synthetic datasets is pivotal for the analysis. Simstudy, a R package, was leveraged in this work as the method for producing datasets of various structures. Given this work is aimed at model performance for binary classification, the response variable 'y' is a function of only the explanatory variables 'x' included in the model euqation shown below. Binary response variable takes on the values of either 1 or 0; thus the formula represents the log of odd or probability of the response being a 1 or 0. As previously stated, the explanatory variable beta is related to the binary response, while the noise variables 'N' are not. The parameter estimates explain the relationship between independent variables 'X' and the dependent variable 'Y', and the 'Y' scale is known as the logit, or log of odds. For each simulation case study explored in the work, the default parameter estimate (e.g. beta) values are uniform at 0.50 and the input features, both noise and explanatory variables, are all continuous and normally distributed. 


\begin{equation}
\log(y) = N_{0} + \beta_{1}X_{1} + .....\beta_{n}X_{n} + N_{n} 
\end{equation}

The user interface for the RShinny application, shown in the figure below, allows users the ability to create multivariate datesets with several input configuraiton options such as specifying the distribution of input features as either gaussian or poisson. Moreoever, users can also modify the magnitudes of the parameter estimates to be non-uniform, allowing for a subset of the explanatory variables to be a more significant predictor of the response variable. 

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{rshiny.png}
\caption{R Shinny Application - Data Simulator}
\end{figure}


\section{Methods and Experiments}

The two machine learning algorithms studied in this work consist of random forest and logistic regression. Both models have been widely implemented in various disciplines for classification and regression purposes. Not only are these algorithms known for their success, but also their simplicity to implement and relatively straightforward to interpet. The functionality of Logistic Regression, a parameter based model, and random forest, a non-parametric model' are discussed in the following section. 

\subsection{Random Forest}


Random forest is an ensemble based learning algorithm which is comprised of 'n' collection of de-correlated decision trees (Hastie, 2009). Built off the idea of bootstrap aggregation which with a method for resampling with replacement in order to reduce variance, random forest uses multiple trees to average (regression) or compute majority votes (classification) in the terminal leaf nodes when making a prediction. Presented by Leo Breiman and built off the idea of decision trees, random forest models resulted significant improvements in prediction accuracy as compared to a single tree by growing 'n' number of trees where each tree in the training set is sampled randomly without replacement (Breiman ,1966). Decision trees consist simply of a tree-like structure where the top node is considered as the root of the tree and is recursively split at a series of decision nodes from the root until the terminal node or decision node is reached. 


\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{decisiontree.png}
\caption{Example of Decision Tree (Lior Rokach et el)}
\end{figure}


As illustrated in the tree structure, the decision tree algorithm is a top down greedy approach by partitioning the dataset into smaller subsets; the result is a tree with a series of decision nodes and leaf node. The decision node has has two or more branches where the features with the highest information gain is split. The predictor variable that yields the highest informatio gain is the root node. The leaf node is represented as a prediction, and in this case, classifying either 1 or 0. Decision trees can handle both categorical and numerical data. First, in order to determine the information gain which is based on the entropy after splitting on an attribute, entropy is computed. Information gain is based on the principles from informaiton theory that uses entropy to compute impurity of datasets. Entropy measures the homogeneity of the subset data; if entropy equals one then the class labels are equally divided while an entropy of zero means the sample is completely homogeneous. 


\begin{equation}
Entropy = -p\log_{2}(p) - q\log_{2}(q)
\end{equation}


Advantages of using tree like learning algorithms allow for training models on large datasets in addition to quantitative and qualitative input variables. Additionally, tree based models can be immune to redundant variables or variables with high correlation which may lead to overfitting in other learning algorithms. Trees have also very few parameters to tune for when training the model and performs relatively well with outliers or missing values in a dataset. However, trees are prone to poor prediction performance; decision trees themselves are prone to overfitting noise in a training set which ultimately leads to results with high variance. In other words, this means the model could accurately predict the same data it was trained on but may not possess the same performance on datasets without the similar patterns and variations in the training set. Even fully grown decision trees are notorious for overfitting and do not generalize well to unseen data; random forest solves the overfitting conundrum by using a combination or "ensemble" of decision trees where the values in the tree are a random, independent, sample. The idea of randomly sampling the without replacement is known as bagging and this results in a different tree being generated to train on; averaging the results from the 'n' number of trees will result in decreasing the variance and establishing a smoother decision boundary (Hastie,  2009). For instance, while using random forest for classification, each tree will give an estimate of the probability of the class label, the probabilities will be averaged over the 'n' trees and the highest yields the predicted class label. In addition to bagging or bootstrap aggregation, in order to further reduces the variance in the decision boundary further, the trees must be completely uncorrelated and the method of bootstrapping alone is not enough. Breiman introduced the idea of randomly sampling 'm' number of features at each decision split in the tree as a way to decorrelate the trees in the random forest algorithm.  


\begin{figure}
\centering
\includegraphics[width=0.90\textwidth]{randomforest.png}
\caption{Example of Decision Tree (Balazs Holczer)}
\end{figure}


\subsection{Logistic Regression}


Linear models are composed of one or multiple independent variables that describes a relationship to a dependent response variable. Mapping qualitative or quantitative input features to a target variable that is attempted to being predicted such as financial, biological, or sociological data is known as supervised learning in machine learning terminology if the labels are known.  One of the most common utilized linear statistical models for discriminant analysis is logistic Regression.

\begin{equation}
\pi_{i} = \beta_{0} + \beta_{1}X_{1} + .....\beta_{n}X_{n}
\end{equation}

Simplicity and interoperability of logistic Regression can occasionally lead to outperforming other sophisticated nonlinear models such as ensemble learners or support vector machines. However, in the event the response variable is drawn from a small sample size, then linear regression models become insufficient and performs poorly for binary responses A number of learning algorithms could be applied to modeling binary classification data types, however the focal point of this work is to examine one linear model, logistic regression. 
 
Unlike the response variable for Linear Regression which is quantitative, the target variable for logistic regression is the posterior probability of being classified in the ith group of a binary or multi-class response (Hastie, 2009). Logistic regression makes several assumptions such as independence, responses (logits) at every level of a subpopulation of the explanatory variable are normally distributed, and constant variance between the responses and all values of the explanatory variable. Intuitively, a transformation to the response variable is applied to yield a continuous probability distribution over the output classes bounded between 0 and 1; this transformation is called to “logistic” or “sigmoid” function where ‘z’ corresponds to log odds divided by the logit (Ng, 2008). The parameter estimates inform whether there is an increase or decrease in the predicted log odds of the response variable that would be predicted by one unit increase or decrease in one of the explanatory variables (e.g. x1), while holding all other explanatory variables constant.

\begin{equation}
\sigma(Z) = \frac{1}{1+\exp^{-z}}
\end{equation}


\begin{figure}
\centering
\includegraphics[scale=1.0]{sigmoid.png}
\caption{Logistic Function}
\end{figure}

For a binary response, the logistic regression model can be expressed by summing over the linear combinations of input features and a corresponding weight plus a bias terms for each instance as shown below in equation (3) and (4).

\begin{equation}
p(y^{(i)} = 1 | x^{(i)},w) = 1-  \frac{1}{1+\exp^{(w^{T}x^{(i)}+b)}}
\end{equation}
\begin{equation}
p(y^{(i)} = 0 | x^{(i)},w) = 1-  \frac{1}{1+\exp^{(w^{T}x^{(i)}+b)}}
\end{equation}


The objective is to find a set of weights such that the negative log likelihood is minimized over the defined training set using optimization techniques such as gradient descent or stochastic gradient descent [3]. Minimizing the negative log likelihood also means maximizing the likelihood or probability the parameter estimate pi of selecting the correct class. The loss function that measures the difference between the ground truth label and the predicted class label is referred to as the cross-entropy. If the prediction is very close to the ground truth label, the loss value will be low. Alternatively, if the prediction is far from the true label, the resulting log loss will be higher.

\begin{equation}
J(\theta) = -\frac{1}{m}\sum p_{i}log(y_{i}) + (1-p_{i})log(1-y_{i})
\end{equation}



\section{Results}

\subsection{Case 1}

The first case we looked into was comparing model performance with respect to change in variance in the explanatory and noise variables.  For this we hypothesized that an increase in variance would strengthen the accuracy for both models.  We set up our tool to run 1000 simulations for 1000 observations of simulated data.  In Figure A, we see the results of accuracy when there are 10 noise variables and 5 explanatory variables.  We can see from this line graph that logistic regression looks to have a slightly higher accuracy over random forest.  However, the p-value in Figure E for the paired two sample t-test was less than 0.05.  When we look at Figure B, we see the spread of accuracy for both models for all 1000 simulations.  There is some overlap of the boxplots which suggests that although the line plots make linear regression look like a higher accuracy, random forest has very similar accuracy.

Figures C and D show the true positive rate and false positive rate respectively.  The true positive rate for both models are nearly the same at each variance level.  However, we can see that the false positive rate for random forest is significantly higher than logistic regression (p-value = 0.63).  Even though both models have the same performance in terms of correctly classifying a true value as true, the false positive rate for random forest is higher than logistic regression.  This causes logistic regression to outperform random forest in terms of overall accuracy at each level of variance.

When we run the exact same test with adding more noise variables, noise = 100, we see the results of the accuracy in Figure F.  By looking at Figure A and Figure F, we see the same trend.  Even looking at the p-value (less than 0.05) in Figure H, we see that there is no significant difference in accuracy between the two models.  In Figure G we see the boxplot spread of accuracy for this simulation.  This also is comparable to Figure B with 10 noise variables where we see a little bit of overlap in the boxplots for each model at each level of variance.  However, with 100 noise variables, the boxplots are much more consistent in that they are all about the same size for each level of variance.  In Figure B, the boxplots for each model are noticeably different sizes.

Figures I and J show the true positive rate and false positive rate respectively with 100 noise variables and 5 explanatory variables over increasing levels of variance in the variables. Interestingly, for variance 0.5 to 2.5 and a lot of noise, random forest has a higher true positive rate.  At around variance = 3.0 and higher, random forest still has a higher true positive rate, but it is not as large of a difference from logistic regression than variance < 2.5.  Unfortunately, in Figure J we can see that the false positive rate for random forest is again higher than logistic regression so the gap in higher true positive rate is not enough to make overall accuracy higher for random forest.


Case 2:

In case 2, we compared model performance with respect to change in the amount of noise in the dataset. We did this by running 1000 simulations on a dataset with the number of noise variables = 1, 5, 10, 20, 40, 60, 80, 100, 150, 200.  In figure A, we see the results of the accuracy for each model when the number of explanatory variables is 5 with 1000 observations.  As we expected, as the amount of noise in the dataset increases, we see the accuracy start to decline for both models.

Figures C and D show the true positive rate and false positive rate respectively.  For true positive rate, when the number of noise variables is the less than or equal to the number of explanatory variables in the dataset, logistic regression is higher.  However, once the number of noise variables exceeds the number of explanatory variables, random forest begins to have a higher true positive rate than logistic regression.  As the amount of noise in the data increases, the false positive rate for both models also increases.  However, the rate of increase in false positive rate for random forest is greater than the rate of increase in false positive rate for logistic regression as noise increases.

We also tested with 10, 20 and 50 explanatory variables in the dataset and saw the same trends in model performance as with 5 explanatory variables.







\section{Ethics}

The disclaimer for utilizing this tool when selecting which machine learning model to implement in a production setting should done so with caution. Currently, the tool does not have certain functionalities to mimic real-world datasets, such as outliers or missing values to name a few. Failure to incorporate these types of characteristics in the simulated dataset can lead to inaccurate conclusions as to which algorithm yielded a better performance and thus any conclusions made from the RShiny tool may not generalize to these types of datasets. Moreover, the tool only considers random forest and logistic regression. As a result, other algorithms such as support vector machines or neural networks could produce higher prediciton accuracies and could be a better model to implement with datsets where the decision boundary is non-linearly seperable. Finally, in the context of the synthetic data generated in the application, there is no legal violations or security concerns. It should be clearly stated that the users should only consider the tool for educational purposes only as this application is still in the development phase. Any decisions drawn from the tool are not endorsed by the authors of this paper.


\section{Conclusions}



\end{document}

